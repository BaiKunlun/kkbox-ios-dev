Accessibility
=============

支援 Accessibility，就是讓具有各種身體障礙的用戶—尤其是視力不良的用戶—
也可以使用你的 App。你現在在開發的是一套音樂 App，但是你可能因為 UI 設
計不良，讓視力不良的用戶無法順利使用你的 App—因為眼睛看不到，所以也沒
辦法用耳朵聽音樂，這實在太沒道理了。

蘋果在 iPhoneOS 3.0 的時候，就加入了三項為視力不佳者服務的設計－如果你
沒有辦法清楚看到 iPhone 上預設大小的文字，你可以開啟畫面的局部放大功能，
同時用三隻手指點按畫面，就可以放大手指所在的區域；如果覺得白底黑字不夠
清楚，可以將畫面反白，切換成黑底白字。

而如果已經完全失去視力，完全無法透過視力操作電腦，iOS 提供一項名為
VoiceOver 的語音功能，開啟後會改變一些觸控的操作行為－原本只要按在畫
面中某個元件上（例如按鈕等），就會使用這一個元件的功能，在開啟
VoiceOver之後，單點一下，系統會先告訴你目前點到的地方是怎樣的東西，之
後再連續點兩下，才是使用這個元件的功能。

因為 VoiceOver 與觸控介面，iOS 裝置變成非常適合盲人使用的資訊設備－在
使用鍵盤滑鼠的操作介面中，不管怎樣，盲人都很難確定目前螢幕上滑鼠指標到
底在什麼地方，但是在觸控介面上，便能夠較為清楚的選擇要點選的是畫面的上
下左右；透過 VoiceOver，盲人朋友無需另外安裝軟體，就可以方便地收取郵
件、閱讀網頁、當你用 iBook 翻閱的書籍時，可以幫你把書中的內容念出來…
等。蘋果在推出 Apple Watch 之後，也一樣實作了 VoiceOver 功能。

在製作軟體時，我們不太需要關心局部放大與反白兩項功能，不過，在
VoiceOver 方面，還是要做一些工作，才能夠完全達成。

如果你的應用程式裡頭，都只有用到 iOS SDK 原本就設計好的那些 UI 元件，
例如 UIButton、UILabel、UISlider … 等等，基本上就已經具備了支援
VoiceOver 的一定能力，在點選到這些元件上的時候，系統就會把裡頭的文字
念出來。

但，假使你不是用文字代表這些元件的意義，而是放入圖片呢？如果圖片來自
bundle 的 resource 裡頭，你用 `[UIImage imageNamed:]` 載入圖片，那，
VoiceOver 會把圖片檔名念出來，恐怕沒有人能聽的懂是什麼意思；而如果圖片
是用程式碼產生，就什麼相關資訊都沒有了。

在 iOS 4.0 之後，無障礙支援又有另外一項意義，就是這個功能與新增的 UI
自動測試（UIAutomation）相關。當你用 Instument 執行某個 iPhone 應用程
式的時候，可以選擇載入一個你之前撰寫好的 Javascript 腳本，接著就會按照
腳本的內容，逐一進行各種 UI 測試項目；腳本的內容大概是，你可以透過
Javascript ，將目前應用程式當前畫面當做物件呼叫，要求回傳畫面上所有可
以使用的 UI 物件列表，然後，要求應用程式自己去點選這些物件。

每個 UI 元件的無障礙資源資訊，在 UI 自動測試中，就會被當做是這個 UI 物
件的 id 使用。比方說，在畫面中有一個叫做「Edit」的按鈕，你從
Javascript 取得的物件列表放在 buttons 這個變數中（型態是 array），那麼，
要取得這個按鈕，可以這麼呼叫： buttons[‘Edit’]。如果要點選這個按鈕，就
是 buttons[‘Edit’].tap()。
